{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BANK MARKETING\n",
    "\n",
    "<br><br>\n",
    "Membros:\n",
    "- Anderson Jesus\n",
    "- Caio Viera\n",
    "- Pedro Correia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> CRIAÇÃO DE MODELO PREDITIVO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicializando sessão do Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/labdata/spark-2.2.1-bin-hadoop2.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession.builder.appName('bank').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\n",
    "    \"hdfs://elephant:8020/user/labdata/bank.csv\",\n",
    "    header=True,\n",
    "    sep=\";\",\n",
    "    inferSchema=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.selectExpr(*[\"`{}` as {}\".format(col, col.replace('.', '_')) for col in data.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo variáveis utilizadas pelo tipo a fim de realizar o encoding necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = [\n",
    "    'job',\n",
    "    'marital',\n",
    "    'education',\n",
    "    'default',\n",
    "    'housing',\n",
    "    'loan',\n",
    "    'contact',\n",
    "    'month',\n",
    "    'day_of_week',\n",
    "    'poutcome'\n",
    "]\n",
    "\n",
    "# não utilizaremos a variável `duration`, que algo não sabido antes da ligação ocorrer\n",
    "# e portanto, não deve ser válida para fins preditivos\n",
    "numericColumns = [\n",
    "    'pdays',\n",
    "    'previous',\n",
    "    'emp_var_rate',\n",
    "    'cons_price_idx',\n",
    "    'cons_conf_idx',\n",
    "    'euribor3m',\n",
    "    'nr_employed'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciando a construção do Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoders e indexadores necessários ao tratamento dos dados\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "# instanciando nossa lista de passos a serem fornecidos ao pipeline\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexação da variável resposta\n",
    "indexer = StringIndexer(\n",
    "    inputCol='y', \n",
    "    outputCol='label'\n",
    ")\n",
    "\n",
    "stages += [indexer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados Categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformações dados categóricos (paralelo pandas: get_dummies)\n",
    "for categoricalCol in categoricalColumns:\n",
    "    # nomes para valores [0:n_cats-1]\n",
    "    indexer = StringIndexer(\n",
    "        inputCol=categoricalCol, \n",
    "        outputCol=categoricalCol+'_index'\n",
    "    )\n",
    "    # criando dummies\n",
    "    encoder = OneHotEncoder(\n",
    "        inputCol=categoricalCol+'_index',\n",
    "        outputCol=categoricalCol+'_class_vec'\n",
    "    )\n",
    "    # inserindo estágios de transformação\n",
    "    stages += [indexer, encoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando variáveis numéricas para o tipo double\n",
    "for numericCol in numericColumns:\n",
    "    data = data.withColumn(numericCol, data[numericCol].cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando assembler, que deixa os dados no formato vetorial \n",
    "# demandado pela biblioteca ML do Spark\n",
    "\n",
    "assembler_inputs = [categoricalCol+'_class_vec' for categoricalCol in categoricalColumns]\n",
    "assembler_inputs += numericColumns\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gradient Boosting Machine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features\",\n",
    "    predictionCol='prediction',\n",
    "    maxIter=60,\n",
    "    stepSize=0.01,\n",
    "    seed=420\n",
    ")\n",
    "\n",
    "stages += [gbt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)\n",
    "pipeline.write().overwrite().save('hdfs://elephant:8020/user/labdata/model/bank-pipeline-model-unfit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando e Validando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observações para treino: 32988\n",
      "Observações para teste:  8200\n"
     ]
    }
   ],
   "source": [
    "# separação de dados em treino e teste\n",
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed=420)\n",
    "\n",
    "print('Observações para treino: {}'.format(trainingData.count()))\n",
    "print('Observações para teste:  {}'.format(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.4 ms, sys: 14.8 ms, total: 77.2 ms\n",
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipelineModel = pipeline.fit(trainingData)\n",
    "pipelineModel.write().overwrite().save('hdfs://elephant:8020/user/labdata/model/bank-pipeline-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gbt = pipelineModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:         0.8998\n",
      "areaUnderROC:     0.7939\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "evaluator_auc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    rawPredictionCol=\"rawPrediction\"\n",
    ")\n",
    "\n",
    "accuracy_gbt = evaluator_accuracy.evaluate(predictions_gbt)\n",
    "print('Accuracy:         {:.4f}'.format(accuracy_gbt))\n",
    "auc_gbt = evaluator_auc.evaluate(predictions_gbt)\n",
    "print(f'areaUnderROC:     {auc_gbt:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|accuracy|precision|recall|\n",
      "+--------+---------+------+\n",
      "|  0.8998|   0.6195|0.2634|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_gbt.select('label', 'prediction').createOrReplaceTempView('predictions')\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    round((tp+tn)/(tp+tn+fp+fn), 4) as accuracy,\n",
    "    round(tp/(tp+fp), 4) as precision,\n",
    "    round(tp/(tp+fn), 4) as recall\n",
    "FROM (\n",
    "    SELECT\n",
    "        sum(tn) as tn,\n",
    "        sum(tp) as tp,\n",
    "        sum(fn) as fn,\n",
    "        sum(fp) as fp\n",
    "    FROM (\n",
    "        SELECT\n",
    "            case when label = 0 and prediction = 0 then 1 else 0 end as tn,\n",
    "            case when label = 1 and prediction = 1 then 1 else 0 end as tp,\n",
    "            case when label = 1 and prediction = 0 then 1 else 0 end as fn,\n",
    "            case when label = 0 and prediction = 1 then 1 else 0 end as fp\n",
    "        FROM\n",
    "            predictions\n",
    "    )\n",
    ")\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GBTClassifier` apresentou maior potencial, apesar de ter um recall ainda muito baixo. \n",
    "\n",
    "Na sequência, vamos buscar realizar um resampling da base, buscando deixar a classe positiva mais prevalente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  y|count|\n",
      "+---+-----+\n",
      "| no| 7356|\n",
      "|yes| 4640|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_res = data.sampleBy('y', fractions={'yes': 1, 'no': 0.2})\n",
    "data_res.groupBy('y').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = data_res.randomSplit([0.8, 0.2], seed=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.7 ms, sys: 16.7 ms, total: 72.4 ms\n",
      "Wall time: 30.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# criando novo modelo com resampling\n",
    "pipelineModel_res = pipeline.fit(trainingData)\n",
    "\n",
    "# salvando o modelo\n",
    "pipelineModel_res.write().overwrite().save('hdfs://elephant:8020/user/labdata/model/bank-pipeline-model-res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_res = pipelineModel_res.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:         0.7782\n"
     ]
    }
   ],
   "source": [
    "accuracy_res = evaluator_accuracy.evaluate(predictions_res)\n",
    "print('Accuracy:         {:.4f}'.format(accuracy_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|accuracy|precision|recall|\n",
      "+--------+---------+------+\n",
      "|  0.7782|   0.7896|0.5868|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_res.select('label', 'prediction').createOrReplaceTempView('predictions_res')\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    round((tp+tn)/(tp+tn+fp+fn), 4) as accuracy,\n",
    "    round(tp/(tp+fp), 4) as precision,\n",
    "    round(tp/(tp+fn), 4) as recall\n",
    "FROM (\n",
    "    SELECT\n",
    "        sum(tn) as tn,\n",
    "        sum(tp) as tp,\n",
    "        sum(fn) as fn,\n",
    "        sum(fp) as fp\n",
    "    FROM (\n",
    "        SELECT\n",
    "            case when label = 0 and prediction = 0 then 1 else 0 end as tn,\n",
    "            case when label = 1 and prediction = 1 then 1 else 0 end as tp,\n",
    "            case when label = 1 and prediction = 0 then 1 else 0 end as fn,\n",
    "            case when label = 0 and prediction = 1 then 1 else 0 end as fp\n",
    "        FROM\n",
    "            predictions_res\n",
    "    )\n",
    ")\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperávamos, o recall apresentou um valor bem mais interessante, demonstrando o potencial da solução, que certamente poderia ser refinada ainda mais a fim de atingir resultados mais expressivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
